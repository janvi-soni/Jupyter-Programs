{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\"\n",
    "Natural language processing (NLP) is a field that focuses on making natural human language usable by computer programs. NLTK, or Natural Language Toolkit, is a Python package that you can use for NLP.\n",
    "A lot of the data that you could be analyzing is unstructured data and contains human-readable text. Before you can analyze that data programmatically, you first need to preprocess it. In this tutorial, you’ll take your first look at the kinds of text preprocessing tasks you can do with NLTK so that you’ll be ready to apply them in future projects. You’ll also see how to do some basic text analysis and create visualizations.\n",
    "If you’re familiar with the basics of using Python and would like to get your feet wet with some NLP, then you’ve come to the right place.\n",
    "\"\"\"\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['by', 'within', 'yours', 'yet', 'twenty', '’re', 'we', 'done', 'n’t', 'least', 'almost', 'either', 'whereafter', 'do', 'without', 'hereby', \"'d\", 'five', 'else', 'thereupon', 'something', 'whoever', 'nowhere', 'them', 'few', 'his', 'full', 'unless', 'meanwhile', 'did', 'thus', 'everyone', 'toward', 'often', '‘re', 'name', 'here', 'anywhere', 'through', 'thereby', 'three', 'until', 'otherwise', 'any', 'are', 'what', 'whereby', 'off', 'anything', 'empty', 'of', 'each', 'quite', 'should', 'take', 'will', 'bottom', 'becoming', 'less', 'those', 'thru', 'and', 'front', 'could', 'himself', 'am', 'sixty', 'as', 'became', 'can', 'anyway', 'seems', 'hundred', 'all', 'mine', 'not', 'me', \"'ve\", 'enough', 'show', 'since', 'towards', 'elsewhere', 'or', 'hence', 'already', 'two', 'may', 'might', 'around', 'whereupon', 'the', 'during', 'n‘t', 'latter', \"'s\", 'noone', 'several', '‘s', 'cannot', 'beforehand', '‘d', 'used', 'former', 'into', 'how', 'out', 'fifty', 'beyond', 'with', 'many', 'although', 'becomes', 'together', 'us', 'must', 're', 'neither', 'yourselves', 'hereupon', 'call', 'whole', 'back', 'sometime', 'most', 'was', 'moreover', 'when', 'whenever', 'along', 'part', 'they', 'four', 'also', 'is', 'that', 'everywhere', 'one', 'yourself', 'amount', 'next', 'there', 'while', 'various', '’ll', 'still', 'once', 'get', 'nine', 'behind', 'does', 'regarding', 'about', 'than', 'being', 'well', 'wherever', 'again', 'you', 'its', 'her', \"'ll\", 'up', 'this', 'before', 'become', 'had', 'their', 'none', 'indeed', 'last', 'others', 'she', 'ten', 'it', 'even', 'much', 'whatever', 'nor', 'side', 'forty', 'therein', 'from', 'over', 'herein', 'everything', 'such', 'a', 'in', 'wherein', 'ours', 'too', 'always', 'formerly', 'doing', 'only', 'another', 'at', \"'re\", 'every', 'six', 'someone', 'further', 'which', 'whether', 'whose', 'on', '‘ll', 'then', 'seem', 'an', 'make', '’m', 'below', 'him', 'eleven', 'to', 'onto', 'be', 'anyone', 'latterly', 'other', 'between', 'somehow', 'who', 'myself', 'because', 'for', 'nothing', 'seemed', 'your', 'nevertheless', \"'m\", 'against', \"n't\", 'amongst', 'hers', 'sometimes', 'no', 'ourselves', 'really', 'afterwards', 'eight', 'he', 'top', 'why', 'ca', 'seeming', 'move', 'under', 'please', 'if', 'say', 'has', '‘m', 'hereafter', 'never', 'beside', 'been', 'keep', 'now', 'more', 'our', 'own', 'thereafter', 'just', 'rather', 'besides', 'put', 'across', 'would', '’d', '’s', 'made', 'fifteen', 'throughout', 'so', 'first', 'third', 'have', 'whom', 'however', 'but', 'upon', 'namely', 'ever', 'whither', 'these', 'nobody', 'some', 'due', 'above', 'thence', 'serious', 'where', 'both', 'see', 'therefore', 'themselves', 'anyhow', 'give', 'somewhere', 'go', 'mostly', 'my', 'itself', 'using', 'herself', '‘ve', 'were', 'whereas', 'down', 'perhaps', 'i', 'twelve', 'very', 'though', 'same', 'via', 'among', 'after', 'except', 'whence', '’ve', 'per', 'alone']\n"
     ]
    }
   ],
   "source": [
    "stopwords=list(STOP_WORDS)\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', 'Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'field', 'that', 'focuses', 'on', 'making', 'natural', 'human', 'language', 'usable', 'by', 'computer', 'programs', '.', 'NLTK', ',', 'or', 'Natural', 'Language', 'Toolkit', ',', 'is', 'a', 'Python', 'package', 'that', 'you', 'can', 'use', 'for', 'NLP', '.', '\\n', 'A', 'lot', 'of', 'the', 'data', 'that', 'you', 'could', 'be', 'analyzing', 'is', 'unstructured', 'data', 'and', 'contains', 'human', '-', 'readable', 'text', '.', 'Before', 'you', 'can', 'analyze', 'that', 'data', 'programmatically', ',', 'you', 'first', 'need', 'to', 'preprocess', 'it', '.', 'In', 'this', 'tutorial', ',', 'you', '’ll', 'take', 'your', 'first', 'look', 'at', 'the', 'kinds', 'of', 'text', 'preprocessing', 'tasks', 'you', 'can', 'do', 'with', 'NLTK', 'so', 'that', 'you', '’ll', 'be', 'ready', 'to', 'apply', 'them', 'in', 'future', 'projects', '.', 'You', '’ll', 'also', 'see', 'how', 'to', 'do', 'some', 'basic', 'text', 'analysis', 'and', 'create', 'visualizations', '.', '\\n', 'If', 'you', '’re', 'familiar', 'with', 'the', 'basics', 'of', 'using', 'Python', 'and', 'would', 'like', 'to', 'get', 'your', 'feet', 'wet', 'with', 'some', 'NLP', ',', 'then', 'you', '’ve', 'come', 'to', 'the', 'right', 'place', '.', '\\n']\n"
     ]
    }
   ],
   "source": [
    "nlp=spacy.load('en_core_web_sm')\n",
    "doc=nlp(text) #we get tokenised word in doc\n",
    "# now make list of tokens\n",
    "tokens=[token.text for token in doc]\n",
    "print(tokens)#punctuations and stop words are also a part of token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~\\n'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuations=punctuation +'\\n'\n",
    "punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_frequencies = {}\n",
    "for word in doc:\n",
    "    if word.text.lower() not in stopwords:\n",
    "        if word.text.lower() not in punctuation:\n",
    "            if word.text not in word_frequencies.keys():\n",
    "                word_frequencies[word.text] = 1 \n",
    "            else:\n",
    "                word_frequencies[word.text] += 1    \n",
    "           \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 4, 'Natural': 2, 'language': 2, 'processing': 1, 'NLP': 3, 'field': 1, 'focuses': 1, 'making': 1, 'natural': 1, 'human': 2, 'usable': 1, 'computer': 1, 'programs': 1, 'NLTK': 2, 'Language': 1, 'Toolkit': 1, 'Python': 2, 'package': 1, 'use': 1, 'lot': 1, 'data': 3, 'analyzing': 1, 'unstructured': 1, 'contains': 1, 'readable': 1, 'text': 3, 'analyze': 1, 'programmatically': 1, 'need': 1, 'preprocess': 1, 'tutorial': 1, 'look': 1, 'kinds': 1, 'preprocessing': 1, 'tasks': 1, 'ready': 1, 'apply': 1, 'future': 1, 'projects': 1, 'basic': 1, 'analysis': 1, 'create': 1, 'visualizations': 1, 'familiar': 1, 'basics': 1, 'like': 1, 'feet': 1, 'wet': 1, 'come': 1, 'right': 1, 'place': 1}\n"
     ]
    }
   ],
   "source": [
    "print(word_frequencies)\n",
    "# find the frequency of filtered words(no stopwords no punctuation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_frequency=max(word_frequencies.values())\n",
    "max_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 1.0, 'Natural': 0.5, 'language': 0.5, 'processing': 0.25, 'NLP': 0.75, 'field': 0.25, 'focuses': 0.25, 'making': 0.25, 'natural': 0.25, 'human': 0.5, 'usable': 0.25, 'computer': 0.25, 'programs': 0.25, 'NLTK': 0.5, 'Language': 0.25, 'Toolkit': 0.25, 'Python': 0.5, 'package': 0.25, 'use': 0.25, 'lot': 0.25, 'data': 0.75, 'analyzing': 0.25, 'unstructured': 0.25, 'contains': 0.25, 'readable': 0.25, 'text': 0.75, 'analyze': 0.25, 'programmatically': 0.25, 'need': 0.25, 'preprocess': 0.25, 'tutorial': 0.25, 'look': 0.25, 'kinds': 0.25, 'preprocessing': 0.25, 'tasks': 0.25, 'ready': 0.25, 'apply': 0.25, 'future': 0.25, 'projects': 0.25, 'basic': 0.25, 'analysis': 0.25, 'create': 0.25, 'visualizations': 0.25, 'familiar': 0.25, 'basics': 0.25, 'like': 0.25, 'feet': 0.25, 'wet': 0.25, 'come': 0.25, 'right': 0.25, 'place': 0.25}\n"
     ]
    }
   ],
   "source": [
    "# now divide the word frequencies by 4 so that the normalised frequencies can be achieved(4/4 =1 which is a maximum normalised frequency\n",
    "# )\n",
    "for word in word_frequencies.keys():\n",
    "    word_frequencies[word]=word_frequencies[word]/max_frequency\n",
    "print(word_frequencies)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      ", Natural language processing (NLP) is a field that focuses on making natural human language usable by computer programs., NLTK, or Natural Language Toolkit, is a Python package that you can use for NLP.\n",
      ", A lot of the data that you could be analyzing is unstructured data and contains human-readable text., Before you can analyze that data programmatically, you first need to preprocess it., In this tutorial, you’ll take your first look at the kinds of text preprocessing tasks you can do with NLTK so that you’ll be ready to apply them in future projects., You’ll also see how to do some basic text analysis and create visualizations.\n",
      ", If you’re familiar with the basics of using Python and would like to get your feet wet with some NLP, then you’ve come to the right place.\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "sentence_tokens=[sent for sent in doc.sents]\n",
    "print(sentence_tokens)\n",
    "# phle hmne normalization se ye nikala ki konsa word imp h \n",
    "# phir ab hum nikal rhe h konsa sentence sbse imp h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_scores={}\n",
    "for sent in sentence_tokens:\n",
    "    for word in sent:\n",
    "        if word.text.lower() in  word_frequencies.keys():\n",
    "            #now we are adding the normalised word frequency(normalized by dividing max_frequency)of each word in a sentence and the word which have highest addition is the imp sentence\n",
    "            if sent not in sentence_scores.keys():\n",
    "                sentence_scores[sent]=word_frequencies[word.text.lower()]\n",
    "            else:\n",
    "                sentence_scores[sent]+=word_frequencies[word.text.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{: 1.0,\n",
       " Natural language processing (NLP) is a field that focuses on making natural human language usable by computer programs.: 3.75,\n",
       " NLTK, or Natural Language Toolkit, is a Python package that you can use for NLP.: 2.25,\n",
       " A lot of the data that you could be analyzing is unstructured data and contains human-readable text.: 4.0,\n",
       " Before you can analyze that data programmatically, you first need to preprocess it.: 1.75,\n",
       " In this tutorial, you’ll take your first look at the kinds of text preprocessing tasks you can do with NLTK so that you’ll be ready to apply them in future projects.: 3.0,\n",
       " You’ll also see how to do some basic text analysis and create visualizations.: 2.75,\n",
       " If you’re familiar with the basics of using Python and would like to get your feet wet with some NLP, then you’ve come to the right place.: 3.0}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from heapq import nlargest\n",
    "select_length=int(len(sentence_tokens)*0.3)\n",
    "select_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary=nlargest(select_length,sentence_scores,key=sentence_scores.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[A lot of the data that you could be analyzing is unstructured data and contains human-readable text.,\n",
       " Natural language processing (NLP) is a field that focuses on making natural human language usable by computer programs.]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A lot of the data that you could be analyzing is unstructured data and contains human-readable text. Natural language processing (NLP) is a field that focuses on making natural human language usable by computer programs.'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_summary=[word.text for word in summary]\n",
    "summary=' '.join(final_summary)\n",
    "summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81f775fc409bf6dd9a2428029fed449f6bdbad6b252340eb0fb01ccd54acbd97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
